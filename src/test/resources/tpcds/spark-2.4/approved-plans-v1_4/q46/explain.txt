== Physical Plan ==
TakeOrderedAndProject(limit=100, orderBy=[c_last_name#1 ASC NULLS FIRST,c_first_name#2 ASC NULLS FIRST,ca_city#3 ASC NULLS FIRST,bought_city#4 ASC NULLS FIRST,ss_ticket_number#5 ASC NULLS FIRST], output=[c_last_name#1,c_first_name#2,ca_city#3,bought_city#4,ss_ticket_number#5,amt#6,profit#7])
+- *(8) Project [c_last_name#1, c_first_name#2, ca_city#3, bought_city#4, ss_ticket_number#5, amt#6, profit#7]
   +- *(8) BroadcastHashJoin [c_current_addr_sk#8], [ca_address_sk#9], Inner, BuildRight, NOT (ca_city#3 = bought_city#4)
      :- *(8) Project [ss_ticket_number#5, bought_city#4, amt#6, profit#7, c_current_addr_sk#8, c_first_name#2, c_last_name#1]
      :  +- *(8) BroadcastHashJoin [ss_customer_sk#10], [c_customer_sk#11], Inner, BuildRight
      :     :- *(8) HashAggregate(keys=[ss_ticket_number#5, ss_customer_sk#10, ss_addr_sk#12, ca_city#3], functions=[sum(UnscaledValue(ss_coupon_amt#13)), sum(UnscaledValue(ss_net_profit#14))])
      :     :  +- Exchange hashpartitioning(ss_ticket_number#5, ss_customer_sk#10, ss_addr_sk#12, ca_city#3, 5)
      :     :     +- *(5) HashAggregate(keys=[ss_ticket_number#5, ss_customer_sk#10, ss_addr_sk#12, ca_city#3], functions=[partial_sum(UnscaledValue(ss_coupon_amt#13)), partial_sum(UnscaledValue(ss_net_profit#14))])
      :     :        +- *(5) Project [ss_customer_sk#10, ss_addr_sk#12, ss_ticket_number#5, ss_coupon_amt#13, ss_net_profit#14, ca_city#3]
      :     :           +- *(5) BroadcastHashJoin [ss_addr_sk#12], [ca_address_sk#9], Inner, BuildRight
      :     :              :- *(5) Project [ss_customer_sk#10, ss_addr_sk#12, ss_ticket_number#5, ss_coupon_amt#13, ss_net_profit#14]
      :     :              :  +- *(5) BroadcastHashJoin [ss_hdemo_sk#15], [hd_demo_sk#16], Inner, BuildRight
      :     :              :     :- *(5) Project [ss_customer_sk#10, ss_hdemo_sk#15, ss_addr_sk#12, ss_ticket_number#5, ss_coupon_amt#13, ss_net_profit#14]
      :     :              :     :  +- *(5) BroadcastHashJoin [ss_store_sk#17], [s_store_sk#18], Inner, BuildRight
      :     :              :     :     :- *(5) Project [ss_customer_sk#10, ss_hdemo_sk#15, ss_addr_sk#12, ss_store_sk#17, ss_ticket_number#5, ss_coupon_amt#13, ss_net_profit#14]
      :     :              :     :     :  +- *(5) BroadcastHashJoin [ss_sold_date_sk#19], [d_date_sk#20], Inner, BuildRight
      :     :              :     :     :     :- *(5) Project [ss_sold_date_sk#19, ss_customer_sk#10, ss_hdemo_sk#15, ss_addr_sk#12, ss_store_sk#17, ss_ticket_number#5, ss_coupon_amt#13, ss_net_profit#14]
      :     :              :     :     :     :  +- *(5) Filter ((((isnotnull(ss_sold_date_sk#19) && isnotnull(ss_store_sk#17)) && isnotnull(ss_hdemo_sk#15)) && isnotnull(ss_addr_sk#12)) && isnotnull(ss_customer_sk#10))
      :     :              :     :     :     :     +- *(5) FileScan parquet default.store_sales[ss_sold_date_sk#19,ss_customer_sk#10,ss_hdemo_sk#15,ss_addr_sk#12,ss_store_sk#17,ss_ticket_number#5,ss_coupon_amt#13,ss_net_profit#14] Batched: true, Format: Parquet, Location: InMemoryFileIndex[file:/C:/Users/apdave/github/hyperspace-1/spark-warehouse/store_sales], PartitionFilters: [], PushedFilters: [IsNotNull(ss_sold_date_sk), IsNotNull(ss_store_sk), IsNotNull(ss_hdemo_sk), IsNotNull(ss_addr_sk..., ReadSchema: struct<ss_sold_date_sk:int,ss_customer_sk:int,ss_hdemo_sk:int,ss_addr_sk:int,ss_store_sk:int,ss_t...
      :     :              :     :     :     +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)))
      :     :              :     :     :        +- *(1) Project [d_date_sk#20]
      :     :              :     :     :           +- *(1) Filter ((d_dow#21 IN (6,0) && d_year#22 IN (1999,2000,2001)) && isnotnull(d_date_sk#20))
      :     :              :     :     :              +- *(1) FileScan parquet default.date_dim[d_date_sk#20,d_year#22,d_dow#21] Batched: true, Format: Parquet, Location: InMemoryFileIndex[file:/C:/Users/apdave/github/hyperspace-1/spark-warehouse/date_dim], PartitionFilters: [], PushedFilters: [In(d_dow, [6,0]), In(d_year, [1999,2000,2001]), IsNotNull(d_date_sk)], ReadSchema: struct<d_date_sk:int,d_year:int,d_dow:int>
      :     :              :     :     +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)))
      :     :              :     :        +- *(2) Project [s_store_sk#18]
      :     :              :     :           +- *(2) Filter (s_city#23 IN (Fairview,Midway) && isnotnull(s_store_sk#18))
      :     :              :     :              +- *(2) FileScan parquet default.store[s_store_sk#18,s_city#23] Batched: true, Format: Parquet, Location: InMemoryFileIndex[file:/C:/Users/apdave/github/hyperspace-1/spark-warehouse/store], PartitionFilters: [], PushedFilters: [In(s_city, [Fairview,Midway]), IsNotNull(s_store_sk)], ReadSchema: struct<s_store_sk:int,s_city:string>
      :     :              :     +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)))
      :     :              :        +- *(3) Project [hd_demo_sk#16]
      :     :              :           +- *(3) Filter (((hd_dep_count#24 = 4) || (hd_vehicle_count#25 = 3)) && isnotnull(hd_demo_sk#16))
      :     :              :              +- *(3) FileScan parquet default.household_demographics[hd_demo_sk#16,hd_dep_count#24,hd_vehicle_count#25] Batched: true, Format: Parquet, Location: InMemoryFileIndex[file:/C:/Users/apdave/github/hyperspace-1/spark-warehouse/household_demographics], PartitionFilters: [], PushedFilters: [Or(EqualTo(hd_dep_count,4),EqualTo(hd_vehicle_count,3)), IsNotNull(hd_demo_sk)], ReadSchema: struct<hd_demo_sk:int,hd_dep_count:int,hd_vehicle_count:int>
      :     :              +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)))
      :     :                 +- *(4) Project [ca_address_sk#9, ca_city#3]
      :     :                    +- *(4) Filter (isnotnull(ca_address_sk#9) && isnotnull(ca_city#3))
      :     :                       +- *(4) FileScan parquet default.customer_address[ca_address_sk#9,ca_city#3] Batched: true, Format: Parquet, Location: InMemoryFileIndex[file:/C:/Users/apdave/github/hyperspace-1/spark-warehouse/customer_address], PartitionFilters: [], PushedFilters: [IsNotNull(ca_address_sk), IsNotNull(ca_city)], ReadSchema: struct<ca_address_sk:int,ca_city:string>
      :     +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)))
      :        +- *(6) Project [c_customer_sk#11, c_current_addr_sk#8, c_first_name#2, c_last_name#1]
      :           +- *(6) Filter (isnotnull(c_customer_sk#11) && isnotnull(c_current_addr_sk#8))
      :              +- *(6) FileScan parquet default.customer[c_customer_sk#11,c_current_addr_sk#8,c_first_name#2,c_last_name#1] Batched: true, Format: Parquet, Location: InMemoryFileIndex[file:/C:/Users/apdave/github/hyperspace-1/spark-warehouse/customer], PartitionFilters: [], PushedFilters: [IsNotNull(c_customer_sk), IsNotNull(c_current_addr_sk)], ReadSchema: struct<c_customer_sk:int,c_current_addr_sk:int,c_first_name:string,c_last_name:string>
      +- ReusedExchange [ca_address_sk#9, ca_city#3], BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)))