== Physical Plan ==
TakeOrderedAndProject(limit=100, orderBy=[CheckOverflow((promote_precision(cast(sum_sales#1 as decimal(22,6))) - promote_precision(cast(avg_monthly_sales#2 as decimal(22,6)))), DecimalType(22,6)) ASC NULLS FIRST,s_store_name#3 ASC NULLS FIRST], output=[i_category#4,i_class#5,i_brand#6,s_store_name#3,s_company_name#7,d_moy#8,sum_sales#1,avg_monthly_sales#2])
+- *(7) Project [i_category#4, i_class#5, i_brand#6, s_store_name#3, s_company_name#7, d_moy#8, sum_sales#1, avg_monthly_sales#2]
   +- *(7) Filter (CASE WHEN NOT (avg_monthly_sales#2 = 0.000000) THEN CheckOverflow((promote_precision(abs(CheckOverflow((promote_precision(cast(sum_sales#1 as decimal(22,6))) - promote_precision(cast(avg_monthly_sales#2 as decimal(22,6)))), DecimalType(22,6)))) / promote_precision(cast(avg_monthly_sales#2 as decimal(22,6)))), DecimalType(38,16)) ELSE null END > 0.1000000000000000)
      +- Window [avg(_w0#9) windowspecdefinition(i_category#4, i_brand#6, s_store_name#3, s_company_name#7, specifiedwindowframe(RowFrame, unboundedpreceding$(), unboundedfollowing$())) AS avg_monthly_sales#2], [i_category#4, i_brand#6, s_store_name#3, s_company_name#7]
         +- *(6) Sort [i_category#4 ASC NULLS FIRST, i_brand#6 ASC NULLS FIRST, s_store_name#3 ASC NULLS FIRST, s_company_name#7 ASC NULLS FIRST], false, 0
            +- Exchange hashpartitioning(i_category#4, i_brand#6, s_store_name#3, s_company_name#7, 5)
               +- *(5) HashAggregate(keys=[i_category#4, i_class#5, i_brand#6, s_store_name#3, s_company_name#7, d_moy#8], functions=[sum(UnscaledValue(ss_sales_price#10))])
                  +- Exchange hashpartitioning(i_category#4, i_class#5, i_brand#6, s_store_name#3, s_company_name#7, d_moy#8, 5)
                     +- *(4) HashAggregate(keys=[i_category#4, i_class#5, i_brand#6, s_store_name#3, s_company_name#7, d_moy#8], functions=[partial_sum(UnscaledValue(ss_sales_price#10))])
                        +- *(4) Project [i_brand#6, i_class#5, i_category#4, ss_sales_price#10, d_moy#8, s_store_name#3, s_company_name#7]
                           +- *(4) BroadcastHashJoin [ss_store_sk#11], [s_store_sk#12], Inner, BuildRight
                              :- *(4) Project [i_brand#6, i_class#5, i_category#4, ss_store_sk#11, ss_sales_price#10, d_moy#8]
                              :  +- *(4) BroadcastHashJoin [ss_sold_date_sk#13], [d_date_sk#14], Inner, BuildRight
                              :     :- *(4) Project [i_brand#6, i_class#5, i_category#4, ss_sold_date_sk#13, ss_store_sk#11, ss_sales_price#10]
                              :     :  +- *(4) BroadcastHashJoin [i_item_sk#15], [ss_item_sk#16], Inner, BuildRight
                              :     :     :- *(4) Project [i_item_sk#15, i_brand#6, i_class#5, i_category#4]
                              :     :     :  +- *(4) Filter (((i_category#4 IN (Books,Electronics,Sports) && i_class#5 IN (computers,stereo,football)) || (i_category#4 IN (Men,Jewelry,Women) && i_class#5 IN (shirts,birdal,dresses))) && isnotnull(i_item_sk#15))
                              :     :     :     +- *(4) FileScan parquet default.item[i_item_sk#15,i_brand#6,i_class#5,i_category#4] Batched: true, Format: Parquet, Location: InMemoryFileIndex[file:/C:/Users/apdave/github/hyperspace-1/spark-warehouse/item], PartitionFilters: [], PushedFilters: [Or(And(In(i_category, [Books,Electronics,Sports]),In(i_class, [computers,stereo,football])),And(..., ReadSchema: struct<i_item_sk:int,i_brand:string,i_class:string,i_category:string>
                              :     :     +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[1, int, true] as bigint)))
                              :     :        +- *(1) Project [ss_sold_date_sk#13, ss_item_sk#16, ss_store_sk#11, ss_sales_price#10]
                              :     :           +- *(1) Filter ((isnotnull(ss_item_sk#16) && isnotnull(ss_sold_date_sk#13)) && isnotnull(ss_store_sk#11))
                              :     :              +- *(1) FileScan parquet default.store_sales[ss_sold_date_sk#13,ss_item_sk#16,ss_store_sk#11,ss_sales_price#10] Batched: true, Format: Parquet, Location: InMemoryFileIndex[file:/C:/Users/apdave/github/hyperspace-1/spark-warehouse/store_sales], PartitionFilters: [], PushedFilters: [IsNotNull(ss_item_sk), IsNotNull(ss_sold_date_sk), IsNotNull(ss_store_sk)], ReadSchema: struct<ss_sold_date_sk:int,ss_item_sk:int,ss_store_sk:int,ss_sales_price:decimal(7,2)>
                              :     +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)))
                              :        +- *(2) Project [d_date_sk#14, d_moy#8]
                              :           +- *(2) Filter ((isnotnull(d_year#17) && (d_year#17 = 1999)) && isnotnull(d_date_sk#14))
                              :              +- *(2) FileScan parquet default.date_dim[d_date_sk#14,d_year#17,d_moy#8] Batched: true, Format: Parquet, Location: InMemoryFileIndex[file:/C:/Users/apdave/github/hyperspace-1/spark-warehouse/date_dim], PartitionFilters: [], PushedFilters: [IsNotNull(d_year), EqualTo(d_year,1999), IsNotNull(d_date_sk)], ReadSchema: struct<d_date_sk:int,d_year:int,d_moy:int>
                              +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)))
                                 +- *(3) Project [s_store_sk#12, s_store_name#3, s_company_name#7]
                                    +- *(3) Filter isnotnull(s_store_sk#12)
                                       +- *(3) FileScan parquet default.store[s_store_sk#12,s_store_name#3,s_company_name#7] Batched: true, Format: Parquet, Location: InMemoryFileIndex[file:/C:/Users/apdave/github/hyperspace-1/spark-warehouse/store], PartitionFilters: [], PushedFilters: [IsNotNull(s_store_sk)], ReadSchema: struct<s_store_sk:int,s_store_name:string,s_company_name:string>