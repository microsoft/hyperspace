== Physical Plan ==
TakeOrderedAndProject(limit=100, orderBy=[i_item_id#1 ASC NULLS FIRST], output=[i_item_id#1,agg1#2,agg2#3,agg3#4,agg4#5])
+- *(6) HashAggregate(keys=[i_item_id#1], functions=[avg(cast(cs_quantity#6 as bigint)), avg(UnscaledValue(cs_list_price#7)), avg(UnscaledValue(cs_coupon_amt#8)), avg(UnscaledValue(cs_sales_price#9))])
   +- Exchange hashpartitioning(i_item_id#1, 5)
      +- *(5) HashAggregate(keys=[i_item_id#1], functions=[partial_avg(cast(cs_quantity#6 as bigint)), partial_avg(UnscaledValue(cs_list_price#7)), partial_avg(UnscaledValue(cs_coupon_amt#8)), partial_avg(UnscaledValue(cs_sales_price#9))])
         +- *(5) Project [cs_quantity#6, cs_list_price#7, cs_sales_price#9, cs_coupon_amt#8, i_item_id#1]
            +- *(5) BroadcastHashJoin [cs_promo_sk#10], [p_promo_sk#11], Inner, BuildRight
               :- *(5) Project [cs_promo_sk#10, cs_quantity#6, cs_list_price#7, cs_sales_price#9, cs_coupon_amt#8, i_item_id#1]
               :  +- *(5) BroadcastHashJoin [cs_item_sk#12], [i_item_sk#13], Inner, BuildRight
               :     :- *(5) Project [cs_item_sk#12, cs_promo_sk#10, cs_quantity#6, cs_list_price#7, cs_sales_price#9, cs_coupon_amt#8]
               :     :  +- *(5) BroadcastHashJoin [cs_sold_date_sk#14], [d_date_sk#15], Inner, BuildRight
               :     :     :- *(5) Project [cs_sold_date_sk#14, cs_item_sk#12, cs_promo_sk#10, cs_quantity#6, cs_list_price#7, cs_sales_price#9, cs_coupon_amt#8]
               :     :     :  +- *(5) BroadcastHashJoin [cs_bill_cdemo_sk#16], [cd_demo_sk#17], Inner, BuildRight
               :     :     :     :- *(5) Project [cs_sold_date_sk#14, cs_bill_cdemo_sk#16, cs_item_sk#12, cs_promo_sk#10, cs_quantity#6, cs_list_price#7, cs_sales_price#9, cs_coupon_amt#8]
               :     :     :     :  +- *(5) Filter (((isnotnull(cs_bill_cdemo_sk#16) && isnotnull(cs_sold_date_sk#14)) && isnotnull(cs_item_sk#12)) && isnotnull(cs_promo_sk#10))
               :     :     :     :     +- *(5) FileScan parquet default.catalog_sales[cs_sold_date_sk#14,cs_bill_cdemo_sk#16,cs_item_sk#12,cs_promo_sk#10,cs_quantity#6,cs_list_price#7,cs_sales_price#9,cs_coupon_amt#8] Batched: true, Format: Parquet, Location: InMemoryFileIndex[file:/C:/Users/apdave/github/hyperspace-1/spark-warehouse/catalog_sales], PartitionFilters: [], PushedFilters: [IsNotNull(cs_bill_cdemo_sk), IsNotNull(cs_sold_date_sk), IsNotNull(cs_item_sk), IsNotNull(cs_pro..., ReadSchema: struct<cs_sold_date_sk:int,cs_bill_cdemo_sk:int,cs_item_sk:int,cs_promo_sk:int,cs_quantity:int,cs...
               :     :     :     +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)))
               :     :     :        +- *(1) Project [cd_demo_sk#17]
               :     :     :           +- *(1) Filter ((((((isnotnull(cd_education_status#18) && isnotnull(cd_gender#19)) && isnotnull(cd_marital_status#20)) && (cd_gender#19 = M)) && (cd_marital_status#20 = S)) && (cd_education_status#18 = College)) && isnotnull(cd_demo_sk#17))
               :     :     :              +- *(1) FileScan parquet default.customer_demographics[cd_demo_sk#17,cd_gender#19,cd_marital_status#20,cd_education_status#18] Batched: true, Format: Parquet, Location: InMemoryFileIndex[file:/C:/Users/apdave/github/hyperspace-1/spark-warehouse/customer_demographics], PartitionFilters: [], PushedFilters: [IsNotNull(cd_education_status), IsNotNull(cd_gender), IsNotNull(cd_marital_status), EqualTo(cd_g..., ReadSchema: struct<cd_demo_sk:int,cd_gender:string,cd_marital_status:string,cd_education_status:string>
               :     :     +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)))
               :     :        +- *(2) Project [d_date_sk#15]
               :     :           +- *(2) Filter ((isnotnull(d_year#21) && (d_year#21 = 2000)) && isnotnull(d_date_sk#15))
               :     :              +- *(2) FileScan parquet default.date_dim[d_date_sk#15,d_year#21] Batched: true, Format: Parquet, Location: InMemoryFileIndex[file:/C:/Users/apdave/github/hyperspace-1/spark-warehouse/date_dim], PartitionFilters: [], PushedFilters: [IsNotNull(d_year), EqualTo(d_year,2000), IsNotNull(d_date_sk)], ReadSchema: struct<d_date_sk:int,d_year:int>
               :     +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)))
               :        +- *(3) Project [i_item_sk#13, i_item_id#1]
               :           +- *(3) Filter isnotnull(i_item_sk#13)
               :              +- *(3) FileScan parquet default.item[i_item_sk#13,i_item_id#1] Batched: true, Format: Parquet, Location: InMemoryFileIndex[file:/C:/Users/apdave/github/hyperspace-1/spark-warehouse/item], PartitionFilters: [], PushedFilters: [IsNotNull(i_item_sk)], ReadSchema: struct<i_item_sk:int,i_item_id:string>
               +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)))
                  +- *(4) Project [p_promo_sk#11]
                     +- *(4) Filter (((p_channel_email#22 = N) || (p_channel_event#23 = N)) && isnotnull(p_promo_sk#11))
                        +- *(4) FileScan parquet default.promotion[p_promo_sk#11,p_channel_email#22,p_channel_event#23] Batched: true, Format: Parquet, Location: InMemoryFileIndex[file:/C:/Users/apdave/github/hyperspace-1/spark-warehouse/promotion], PartitionFilters: [], PushedFilters: [Or(EqualTo(p_channel_email,N),EqualTo(p_channel_event,N)), IsNotNull(p_promo_sk)], ReadSchema: struct<p_promo_sk:int,p_channel_email:string,p_channel_event:string>