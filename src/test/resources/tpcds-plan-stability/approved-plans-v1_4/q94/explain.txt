== Physical Plan ==
TakeOrderedAndProject(limit=100, orderBy=[order count #1 ASC NULLS FIRST], output=[order count #1,total shipping cost #2,total net profit #3])
+- *(8) HashAggregate(keys=[], functions=[sum(UnscaledValue(ws_ext_ship_cost#4)), sum(UnscaledValue(ws_net_profit#5)), count(distinct ws_order_number#6)])
   +- Exchange SinglePartition
      +- *(7) HashAggregate(keys=[], functions=[merge_sum(UnscaledValue(ws_ext_ship_cost#4)), merge_sum(UnscaledValue(ws_net_profit#5)), partial_count(distinct ws_order_number#6)])
         +- *(7) HashAggregate(keys=[ws_order_number#6], functions=[merge_sum(UnscaledValue(ws_ext_ship_cost#4)), merge_sum(UnscaledValue(ws_net_profit#5))])
            +- Exchange hashpartitioning(ws_order_number#6, 200)
               +- *(6) HashAggregate(keys=[ws_order_number#6], functions=[partial_sum(UnscaledValue(ws_ext_ship_cost#4)), partial_sum(UnscaledValue(ws_net_profit#5))])
                  +- *(6) Project [ws_order_number#6, ws_ext_ship_cost#4, ws_net_profit#5]
                     +- *(6) BroadcastHashJoin [ws_web_site_sk#7], [web_site_sk#8], Inner, BuildRight
                        :- *(6) Project [ws_web_site_sk#7, ws_order_number#6, ws_ext_ship_cost#4, ws_net_profit#5]
                        :  +- *(6) BroadcastHashJoin [ws_ship_addr_sk#9], [ca_address_sk#10], Inner, BuildRight
                        :     :- *(6) Project [ws_ship_addr_sk#9, ws_web_site_sk#7, ws_order_number#6, ws_ext_ship_cost#4, ws_net_profit#5]
                        :     :  +- *(6) BroadcastHashJoin [ws_ship_date_sk#11], [d_date_sk#12], Inner, BuildRight
                        :     :     :- *(6) BroadcastHashJoin [cast(ws_order_number#6 as bigint)], [wr_order_number#13], LeftAnti, BuildRight
                        :     :     :  :- *(6) Project [ws_ship_date_sk#11, ws_ship_addr_sk#9, ws_web_site_sk#7, ws_order_number#6, ws_ext_ship_cost#4, ws_net_profit#5]
                        :     :     :  :  +- *(6) BroadcastHashJoin [ws_order_number#6], [ws_order_number#6#14], LeftSemi, BuildRight, NOT (ws_warehouse_sk#15 = ws_warehouse_sk#15#16)
                        :     :     :  :     :- *(6) Project [ws_ship_date_sk#11, ws_ship_addr_sk#9, ws_web_site_sk#7, ws_warehouse_sk#15, ws_order_number#6, ws_ext_ship_cost#4, ws_net_profit#5]
                        :     :     :  :     :  +- *(6) Filter ((isnotnull(ws_ship_date_sk#11) && isnotnull(ws_ship_addr_sk#9)) && isnotnull(ws_web_site_sk#7))
                        :     :     :  :     :     +- *(6) FileScan parquet default.web_sales[ws_ship_date_sk#11,ws_ship_addr_sk#9,ws_web_site_sk#7,ws_warehouse_sk#15,ws_order_number#6,ws_ext_ship_cost#4,ws_net_profit#5] Batched: true, Format: Parquet, Location: InMemoryFileIndex[file:/C:/Users/apdave/github/hyperspace-1/spark-warehouse/web_sales], PartitionFilters: [], PushedFilters: [IsNotNull(ws_ship_date_sk), IsNotNull(ws_ship_addr_sk), IsNotNull(ws_web_site_sk)], ReadSchema: struct<ws_ship_date_sk:int,ws_ship_addr_sk:int,ws_web_site_sk:int,ws_warehouse_sk:int,ws_order_nu...
                        :     :     :  :     +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[1, int, true] as bigint)))
                        :     :     :  :        +- *(1) Project [ws_warehouse_sk#15 AS ws_warehouse_sk#15#16, ws_order_number#6 AS ws_order_number#6#14]
                        :     :     :  :           +- *(1) FileScan parquet default.web_sales[ws_warehouse_sk#15,ws_order_number#6] Batched: true, Format: Parquet, Location: InMemoryFileIndex[file:/C:/Users/apdave/github/hyperspace-1/spark-warehouse/web_sales], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<ws_warehouse_sk:int,ws_order_number:int>
                        :     :     :  +- BroadcastExchange HashedRelationBroadcastMode(List(input[0, bigint, true]))
                        :     :     :     +- *(2) FileScan parquet default.web_returns[wr_order_number#13] Batched: true, Format: Parquet, Location: InMemoryFileIndex[file:/C:/Users/apdave/github/hyperspace-1/spark-warehouse/web_returns], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<wr_order_number:bigint>
                        :     :     +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)))
                        :     :        +- *(3) Project [d_date_sk#12]
                        :     :           +- *(3) Filter (((isnotnull(d_date#17) && (cast(d_date#17 as string) >= 1999-02-01)) && (d_date#17 <= 10683)) && isnotnull(d_date_sk#12))
                        :     :              +- *(3) FileScan parquet default.date_dim[d_date_sk#12,d_date#17] Batched: true, Format: Parquet, Location: InMemoryFileIndex[file:/C:/Users/apdave/github/hyperspace-1/spark-warehouse/date_dim], PartitionFilters: [], PushedFilters: [IsNotNull(d_date), LessThanOrEqual(d_date,1999-04-02), IsNotNull(d_date_sk)], ReadSchema: struct<d_date_sk:int,d_date:date>
                        :     +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)))
                        :        +- *(4) Project [ca_address_sk#10]
                        :           +- *(4) Filter ((isnotnull(ca_state#18) && (ca_state#18 = IL)) && isnotnull(ca_address_sk#10))
                        :              +- *(4) FileScan parquet default.customer_address[ca_address_sk#10,ca_state#18] Batched: true, Format: Parquet, Location: InMemoryFileIndex[file:/C:/Users/apdave/github/hyperspace-1/spark-warehouse/customer_address], PartitionFilters: [], PushedFilters: [IsNotNull(ca_state), EqualTo(ca_state,IL), IsNotNull(ca_address_sk)], ReadSchema: struct<ca_address_sk:int,ca_state:string>
                        +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)))
                           +- *(5) Project [web_site_sk#8]
                              +- *(5) Filter ((isnotnull(web_company_name#19) && (web_company_name#19 = pri)) && isnotnull(web_site_sk#8))
                                 +- *(5) FileScan parquet default.web_site[web_site_sk#8,web_company_name#19] Batched: true, Format: Parquet, Location: InMemoryFileIndex[file:/C:/Users/apdave/github/hyperspace-1/spark-warehouse/web_site], PartitionFilters: [], PushedFilters: [IsNotNull(web_company_name), EqualTo(web_company_name,pri), IsNotNull(web_site_sk)], ReadSchema: struct<web_site_sk:int,web_company_name:string>