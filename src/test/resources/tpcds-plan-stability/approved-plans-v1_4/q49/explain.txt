== Physical Plan ==
TakeOrderedAndProject(limit=100, orderBy=[channel#1 ASC NULLS FIRST,return_rank#2 ASC NULLS FIRST,currency_rank#3 ASC NULLS FIRST], output=[channel#1,item#4,return_ratio#5,return_rank#2,currency_rank#3])
+- *(23) HashAggregate(keys=[channel#1, item#4, return_ratio#5, return_rank#2, currency_rank#3], functions=[])
   +- Exchange hashpartitioning(channel#1, item#4, return_ratio#5, return_rank#2, currency_rank#3, 5)
      +- *(22) HashAggregate(keys=[channel#1, item#4, return_ratio#5, return_rank#2, currency_rank#3], functions=[])
         +- Union
            :- *(7) Project [web AS channel#1, item#4, return_ratio#5, return_rank#2, currency_rank#3]
            :  +- *(7) Filter ((return_rank#2 <= 10) || (currency_rank#3 <= 10))
            :     +- Window [rank(return_ratio#5) windowspecdefinition(return_ratio#5 ASC NULLS FIRST, specifiedwindowframe(RowFrame, unboundedpreceding$(), currentrow$())) AS return_rank#2], [return_ratio#5 ASC NULLS FIRST]
            :        +- *(6) Sort [return_ratio#5 ASC NULLS FIRST], false, 0
            :           +- *(6) Project [item#4, return_ratio#5, currency_rank#3]
            :              +- Window [rank(currency_ratio#6) windowspecdefinition(currency_ratio#6 ASC NULLS FIRST, specifiedwindowframe(RowFrame, unboundedpreceding$(), currentrow$())) AS currency_rank#3], [currency_ratio#6 ASC NULLS FIRST]
            :                 +- *(5) Sort [currency_ratio#6 ASC NULLS FIRST], false, 0
            :                    +- Exchange SinglePartition
            :                       +- *(4) HashAggregate(keys=[ws_item_sk#7], functions=[sum(cast(coalesce(wr_return_quantity#8, 0) as bigint)), sum(cast(coalesce(ws_quantity#9, 0) as bigint)), sum(coalesce(cast(wr_return_amt#10 as decimal(12,2)), 0.00)), sum(coalesce(cast(ws_net_paid#11 as decimal(12,2)), 0.00))])
            :                          +- Exchange hashpartitioning(ws_item_sk#7, 5)
            :                             +- *(3) HashAggregate(keys=[ws_item_sk#7], functions=[partial_sum(cast(coalesce(wr_return_quantity#8, 0) as bigint)), partial_sum(cast(coalesce(ws_quantity#9, 0) as bigint)), partial_sum(coalesce(cast(wr_return_amt#10 as decimal(12,2)), 0.00)), partial_sum(coalesce(cast(ws_net_paid#11 as decimal(12,2)), 0.00))])
            :                                +- *(3) Project [ws_item_sk#7, ws_quantity#9, ws_net_paid#11, wr_return_quantity#8, wr_return_amt#10]
            :                                   +- *(3) BroadcastHashJoin [ws_sold_date_sk#12], [d_date_sk#13], Inner, BuildRight
            :                                      :- *(3) Project [ws_sold_date_sk#12, ws_item_sk#7, ws_quantity#9, ws_net_paid#11, wr_return_quantity#8, wr_return_amt#10]
            :                                      :  +- *(3) BroadcastHashJoin [cast(ws_order_number#14 as bigint), cast(ws_item_sk#7 as bigint)], [wr_order_number#15, wr_item_sk#16], Inner, BuildRight
            :                                      :     :- *(3) Project [ws_sold_date_sk#12, ws_item_sk#7, ws_order_number#14, ws_quantity#9, ws_net_paid#11]
            :                                      :     :  +- *(3) Filter ((((((((isnotnull(ws_net_paid#11) && isnotnull(ws_quantity#9)) && isnotnull(ws_net_profit#17)) && (ws_net_profit#17 > 1.00)) && (ws_net_paid#11 > 0.00)) && (ws_quantity#9 > 0)) && isnotnull(ws_order_number#14)) && isnotnull(ws_item_sk#7)) && isnotnull(ws_sold_date_sk#12))
            :                                      :     :     +- *(3) FileScan parquet default.web_sales[ws_sold_date_sk#12,ws_item_sk#7,ws_order_number#14,ws_quantity#9,ws_net_paid#11,ws_net_profit#17] Batched: true, Format: Parquet, Location: InMemoryFileIndex[file:/C:/Users/apdave/github/hyperspace-1/spark-warehouse/web_sales], PartitionFilters: [], PushedFilters: [IsNotNull(ws_net_paid), IsNotNull(ws_quantity), IsNotNull(ws_net_profit), GreaterThan(ws_net_pro..., ReadSchema: struct<ws_sold_date_sk:int,ws_item_sk:int,ws_order_number:int,ws_quantity:int,ws_net_paid:decimal...
            :                                      :     +- BroadcastExchange HashedRelationBroadcastMode(List(input[1, bigint, true], input[0, bigint, true]))
            :                                      :        +- *(1) Project [wr_item_sk#16, wr_order_number#15, wr_return_quantity#8, wr_return_amt#10]
            :                                      :           +- *(1) Filter (((isnotnull(wr_return_amt#10) && (wr_return_amt#10 > 10000.00)) && isnotnull(wr_order_number#15)) && isnotnull(wr_item_sk#16))
            :                                      :              +- *(1) FileScan parquet default.web_returns[wr_item_sk#16,wr_order_number#15,wr_return_quantity#8,wr_return_amt#10] Batched: true, Format: Parquet, Location: InMemoryFileIndex[file:/C:/Users/apdave/github/hyperspace-1/spark-warehouse/web_returns], PartitionFilters: [], PushedFilters: [IsNotNull(wr_return_amt), GreaterThan(wr_return_amt,10000.00), IsNotNull(wr_order_number), IsNot..., ReadSchema: struct<wr_item_sk:bigint,wr_order_number:bigint,wr_return_quantity:int,wr_return_amt:decimal(7,2)>
            :                                      +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)))
            :                                         +- *(2) Project [d_date_sk#13]
            :                                            +- *(2) Filter ((((isnotnull(d_year#18) && isnotnull(d_moy#19)) && (d_year#18 = 2001)) && (d_moy#19 = 12)) && isnotnull(d_date_sk#13))
            :                                               +- *(2) FileScan parquet default.date_dim[d_date_sk#13,d_year#18,d_moy#19] Batched: true, Format: Parquet, Location: InMemoryFileIndex[file:/C:/Users/apdave/github/hyperspace-1/spark-warehouse/date_dim], PartitionFilters: [], PushedFilters: [IsNotNull(d_year), IsNotNull(d_moy), EqualTo(d_year,2001), EqualTo(d_moy,12), IsNotNull(d_date_sk)], ReadSchema: struct<d_date_sk:int,d_year:int,d_moy:int>
            :- *(14) Project [catalog AS channel#20, item#21, return_ratio#22, return_rank#23, currency_rank#24]
            :  +- *(14) Filter ((return_rank#23 <= 10) || (currency_rank#24 <= 10))
            :     +- Window [rank(currency_ratio#25) windowspecdefinition(currency_ratio#25 ASC NULLS FIRST, specifiedwindowframe(RowFrame, unboundedpreceding$(), currentrow$())) AS currency_rank#24], [currency_ratio#25 ASC NULLS FIRST]
            :        +- *(13) Sort [currency_ratio#25 ASC NULLS FIRST], false, 0
            :           +- Window [rank(return_ratio#22) windowspecdefinition(return_ratio#22 ASC NULLS FIRST, specifiedwindowframe(RowFrame, unboundedpreceding$(), currentrow$())) AS return_rank#23], [return_ratio#22 ASC NULLS FIRST]
            :              +- *(12) Sort [return_ratio#22 ASC NULLS FIRST], false, 0
            :                 +- Exchange SinglePartition
            :                    +- *(11) HashAggregate(keys=[cs_item_sk#26], functions=[sum(cast(coalesce(cr_return_quantity#27, 0) as bigint)), sum(cast(coalesce(cs_quantity#28, 0) as bigint)), sum(coalesce(cast(cr_return_amount#29 as decimal(12,2)), 0.00)), sum(coalesce(cast(cs_net_paid#30 as decimal(12,2)), 0.00))])
            :                       +- Exchange hashpartitioning(cs_item_sk#26, 5)
            :                          +- *(10) HashAggregate(keys=[cs_item_sk#26], functions=[partial_sum(cast(coalesce(cr_return_quantity#27, 0) as bigint)), partial_sum(cast(coalesce(cs_quantity#28, 0) as bigint)), partial_sum(coalesce(cast(cr_return_amount#29 as decimal(12,2)), 0.00)), partial_sum(coalesce(cast(cs_net_paid#30 as decimal(12,2)), 0.00))])
            :                             +- *(10) Project [cs_item_sk#26, cs_quantity#28, cs_net_paid#30, cr_return_quantity#27, cr_return_amount#29]
            :                                +- *(10) BroadcastHashJoin [cs_sold_date_sk#31], [d_date_sk#13], Inner, BuildRight
            :                                   :- *(10) Project [cs_sold_date_sk#31, cs_item_sk#26, cs_quantity#28, cs_net_paid#30, cr_return_quantity#27, cr_return_amount#29]
            :                                   :  +- *(10) BroadcastHashJoin [cs_order_number#32, cs_item_sk#26], [cr_order_number#33, cr_item_sk#34], Inner, BuildRight
            :                                   :     :- *(10) Project [cs_sold_date_sk#31, cs_item_sk#26, cs_order_number#32, cs_quantity#28, cs_net_paid#30]
            :                                   :     :  +- *(10) Filter ((((((((isnotnull(cs_net_paid#30) && isnotnull(cs_quantity#28)) && isnotnull(cs_net_profit#35)) && (cs_net_profit#35 > 1.00)) && (cs_net_paid#30 > 0.00)) && (cs_quantity#28 > 0)) && isnotnull(cs_item_sk#26)) && isnotnull(cs_order_number#32)) && isnotnull(cs_sold_date_sk#31))
            :                                   :     :     +- *(10) FileScan parquet default.catalog_sales[cs_sold_date_sk#31,cs_item_sk#26,cs_order_number#32,cs_quantity#28,cs_net_paid#30,cs_net_profit#35] Batched: true, Format: Parquet, Location: InMemoryFileIndex[file:/C:/Users/apdave/github/hyperspace-1/spark-warehouse/catalog_sales], PartitionFilters: [], PushedFilters: [IsNotNull(cs_net_paid), IsNotNull(cs_quantity), IsNotNull(cs_net_profit), GreaterThan(cs_net_pro..., ReadSchema: struct<cs_sold_date_sk:int,cs_item_sk:int,cs_order_number:int,cs_quantity:int,cs_net_paid:decimal...
            :                                   :     +- BroadcastExchange HashedRelationBroadcastMode(List((shiftleft(cast(input[1, int, true] as bigint), 32) | (cast(input[0, int, true] as bigint) & 4294967295))))
            :                                   :        +- *(8) Project [cr_item_sk#34, cr_order_number#33, cr_return_quantity#27, cr_return_amount#29]
            :                                   :           +- *(8) Filter (((isnotnull(cr_return_amount#29) && (cr_return_amount#29 > 10000.00)) && isnotnull(cr_item_sk#34)) && isnotnull(cr_order_number#33))
            :                                   :              +- *(8) FileScan parquet default.catalog_returns[cr_item_sk#34,cr_order_number#33,cr_return_quantity#27,cr_return_amount#29] Batched: true, Format: Parquet, Location: InMemoryFileIndex[file:/C:/Users/apdave/github/hyperspace-1/spark-warehouse/catalog_returns], PartitionFilters: [], PushedFilters: [IsNotNull(cr_return_amount), GreaterThan(cr_return_amount,10000.00), IsNotNull(cr_item_sk), IsNo..., ReadSchema: struct<cr_item_sk:int,cr_order_number:int,cr_return_quantity:int,cr_return_amount:decimal(7,2)>
            :                                   +- ReusedExchange [d_date_sk#13], BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)))
            +- *(21) Project [store AS channel#36, item#37, return_ratio#38, return_rank#39, currency_rank#40]
               +- *(21) Filter ((return_rank#39 <= 10) || (currency_rank#40 <= 10))
                  +- Window [rank(return_ratio#38) windowspecdefinition(return_ratio#38 ASC NULLS FIRST, specifiedwindowframe(RowFrame, unboundedpreceding$(), currentrow$())) AS return_rank#39], [return_ratio#38 ASC NULLS FIRST]
                     +- *(20) Sort [return_ratio#38 ASC NULLS FIRST], false, 0
                        +- *(20) Project [item#37, return_ratio#38, currency_rank#40]
                           +- Window [rank(currency_ratio#41) windowspecdefinition(currency_ratio#41 ASC NULLS FIRST, specifiedwindowframe(RowFrame, unboundedpreceding$(), currentrow$())) AS currency_rank#40], [currency_ratio#41 ASC NULLS FIRST]
                              +- *(19) Sort [currency_ratio#41 ASC NULLS FIRST], false, 0
                                 +- Exchange SinglePartition
                                    +- *(18) HashAggregate(keys=[ss_item_sk#42], functions=[sum(cast(coalesce(sr_return_quantity#43, 0) as bigint)), sum(cast(coalesce(ss_quantity#44, 0) as bigint)), sum(coalesce(cast(sr_return_amt#45 as decimal(12,2)), 0.00)), sum(coalesce(cast(ss_net_paid#46 as decimal(12,2)), 0.00))])
                                       +- Exchange hashpartitioning(ss_item_sk#42, 5)
                                          +- *(17) HashAggregate(keys=[ss_item_sk#42], functions=[partial_sum(cast(coalesce(sr_return_quantity#43, 0) as bigint)), partial_sum(cast(coalesce(ss_quantity#44, 0) as bigint)), partial_sum(coalesce(cast(sr_return_amt#45 as decimal(12,2)), 0.00)), partial_sum(coalesce(cast(ss_net_paid#46 as decimal(12,2)), 0.00))])
                                             +- *(17) Project [ss_item_sk#42, ss_quantity#44, ss_net_paid#46, sr_return_quantity#43, sr_return_amt#45]
                                                +- *(17) BroadcastHashJoin [ss_sold_date_sk#47], [d_date_sk#13], Inner, BuildRight
                                                   :- *(17) Project [ss_sold_date_sk#47, ss_item_sk#42, ss_quantity#44, ss_net_paid#46, sr_return_quantity#43, sr_return_amt#45]
                                                   :  +- *(17) BroadcastHashJoin [cast(ss_ticket_number#48 as bigint), cast(ss_item_sk#42 as bigint)], [sr_ticket_number#49, sr_item_sk#50], Inner, BuildRight
                                                   :     :- *(17) Project [ss_sold_date_sk#47, ss_item_sk#42, ss_ticket_number#48, ss_quantity#44, ss_net_paid#46]
                                                   :     :  +- *(17) Filter ((((((((isnotnull(ss_net_profit#51) && isnotnull(ss_quantity#44)) && isnotnull(ss_net_paid#46)) && (ss_net_profit#51 > 1.00)) && (ss_net_paid#46 > 0.00)) && (ss_quantity#44 > 0)) && isnotnull(ss_ticket_number#48)) && isnotnull(ss_item_sk#42)) && isnotnull(ss_sold_date_sk#47))
                                                   :     :     +- *(17) FileScan parquet default.store_sales[ss_sold_date_sk#47,ss_item_sk#42,ss_ticket_number#48,ss_quantity#44,ss_net_paid#46,ss_net_profit#51] Batched: true, Format: Parquet, Location: InMemoryFileIndex[file:/C:/Users/apdave/github/hyperspace-1/spark-warehouse/store_sales], PartitionFilters: [], PushedFilters: [IsNotNull(ss_net_profit), IsNotNull(ss_quantity), IsNotNull(ss_net_paid), GreaterThan(ss_net_pro..., ReadSchema: struct<ss_sold_date_sk:int,ss_item_sk:int,ss_ticket_number:int,ss_quantity:int,ss_net_paid:decima...
                                                   :     +- BroadcastExchange HashedRelationBroadcastMode(List(input[1, bigint, true], input[0, bigint, true]))
                                                   :        +- *(15) Project [sr_item_sk#50, sr_ticket_number#49, sr_return_quantity#43, sr_return_amt#45]
                                                   :           +- *(15) Filter (((isnotnull(sr_return_amt#45) && (sr_return_amt#45 > 10000.00)) && isnotnull(sr_ticket_number#49)) && isnotnull(sr_item_sk#50))
                                                   :              +- *(15) FileScan parquet default.store_returns[sr_item_sk#50,sr_ticket_number#49,sr_return_quantity#43,sr_return_amt#45] Batched: true, Format: Parquet, Location: InMemoryFileIndex[file:/C:/Users/apdave/github/hyperspace-1/spark-warehouse/store_returns], PartitionFilters: [], PushedFilters: [IsNotNull(sr_return_amt), GreaterThan(sr_return_amt,10000.00), IsNotNull(sr_ticket_number), IsNo..., ReadSchema: struct<sr_item_sk:bigint,sr_ticket_number:bigint,sr_return_quantity:int,sr_return_amt:decimal(7,2)>
                                                   +- ReusedExchange [d_date_sk#13], BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)))