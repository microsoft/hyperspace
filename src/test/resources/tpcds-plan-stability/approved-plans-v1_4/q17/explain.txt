== Physical Plan ==
TakeOrderedAndProject(limit=100, orderBy=[i_item_id#1 ASC NULLS FIRST,i_item_desc#2 ASC NULLS FIRST,s_state#3 ASC NULLS FIRST], output=[i_item_id#1,i_item_desc#2,s_state#3,store_sales_quantitycount#4,store_sales_quantityave#5,store_sales_quantitystdev#6,store_sales_quantitycov#7,as_store_returns_quantitycount#8,as_store_returns_quantityave#9,as_store_returns_quantitystdev#10,store_returns_quantitycov#11,catalog_sales_quantitycount#12,catalog_sales_quantityave#13,catalog_sales_quantitystdev#14,catalog_sales_quantitycov#15])
+- *(9) HashAggregate(keys=[i_item_id#1, i_item_desc#2, s_state#3], functions=[count(ss_quantity#16), avg(cast(ss_quantity#16 as bigint)), stddev_samp(cast(ss_quantity#16 as double)), count(sr_return_quantity#17), avg(cast(sr_return_quantity#17 as bigint)), stddev_samp(cast(sr_return_quantity#17 as double)), count(cs_quantity#18), avg(cast(cs_quantity#18 as bigint)), stddev_samp(cast(cs_quantity#18 as double))])
   +- Exchange hashpartitioning(i_item_id#1, i_item_desc#2, s_state#3, 5)
      +- *(8) HashAggregate(keys=[i_item_id#1, i_item_desc#2, s_state#3], functions=[partial_count(ss_quantity#16), partial_avg(cast(ss_quantity#16 as bigint)), partial_stddev_samp(cast(ss_quantity#16 as double)), partial_count(sr_return_quantity#17), partial_avg(cast(sr_return_quantity#17 as bigint)), partial_stddev_samp(cast(sr_return_quantity#17 as double)), partial_count(cs_quantity#18), partial_avg(cast(cs_quantity#18 as bigint)), partial_stddev_samp(cast(cs_quantity#18 as double))])
         +- *(8) Project [ss_quantity#16, sr_return_quantity#17, cs_quantity#18, s_state#3, i_item_id#1, i_item_desc#2]
            +- *(8) BroadcastHashJoin [ss_item_sk#19], [i_item_sk#20], Inner, BuildRight
               :- *(8) Project [ss_item_sk#19, ss_quantity#16, sr_return_quantity#17, cs_quantity#18, s_state#3]
               :  +- *(8) BroadcastHashJoin [ss_store_sk#21], [s_store_sk#22], Inner, BuildRight
               :     :- *(8) Project [ss_item_sk#19, ss_store_sk#21, ss_quantity#16, sr_return_quantity#17, cs_quantity#18]
               :     :  +- *(8) BroadcastHashJoin [cs_sold_date_sk#23], [d_date_sk#24], Inner, BuildRight
               :     :     :- *(8) Project [ss_item_sk#19, ss_store_sk#21, ss_quantity#16, sr_return_quantity#17, cs_sold_date_sk#23, cs_quantity#18]
               :     :     :  +- *(8) BroadcastHashJoin [sr_returned_date_sk#25], [cast(d_date_sk#26 as bigint)], Inner, BuildRight
               :     :     :     :- *(8) Project [ss_item_sk#19, ss_store_sk#21, ss_quantity#16, sr_returned_date_sk#25, sr_return_quantity#17, cs_sold_date_sk#23, cs_quantity#18]
               :     :     :     :  +- *(8) BroadcastHashJoin [ss_sold_date_sk#27], [d_date_sk#28], Inner, BuildRight
               :     :     :     :     :- *(8) Project [ss_sold_date_sk#27, ss_item_sk#19, ss_store_sk#21, ss_quantity#16, sr_returned_date_sk#25, sr_return_quantity#17, cs_sold_date_sk#23, cs_quantity#18]
               :     :     :     :     :  +- *(8) BroadcastHashJoin [sr_customer_sk#29, sr_item_sk#30], [cast(cs_bill_customer_sk#31 as bigint), cast(cs_item_sk#32 as bigint)], Inner, BuildRight
               :     :     :     :     :     :- *(8) Project [ss_sold_date_sk#27, ss_item_sk#19, ss_store_sk#21, ss_quantity#16, sr_returned_date_sk#25, sr_item_sk#30, sr_customer_sk#29, sr_return_quantity#17]
               :     :     :     :     :     :  +- *(8) BroadcastHashJoin [cast(ss_customer_sk#33 as bigint), cast(ss_item_sk#19 as bigint), cast(ss_ticket_number#34 as bigint)], [sr_customer_sk#29, sr_item_sk#30, sr_ticket_number#35], Inner, BuildRight
               :     :     :     :     :     :     :- *(8) Project [ss_sold_date_sk#27, ss_item_sk#19, ss_customer_sk#33, ss_store_sk#21, ss_ticket_number#34, ss_quantity#16]
               :     :     :     :     :     :     :  +- *(8) Filter ((((isnotnull(ss_ticket_number#34) && isnotnull(ss_item_sk#19)) && isnotnull(ss_customer_sk#33)) && isnotnull(ss_sold_date_sk#27)) && isnotnull(ss_store_sk#21))
               :     :     :     :     :     :     :     +- *(8) FileScan parquet default.store_sales[ss_sold_date_sk#27,ss_item_sk#19,ss_customer_sk#33,ss_store_sk#21,ss_ticket_number#34,ss_quantity#16] Batched: true, Format: Parquet, Location: InMemoryFileIndex[file:/C:/Users/apdave/github/hyperspace-1/spark-warehouse/store_sales], PartitionFilters: [], PushedFilters: [IsNotNull(ss_ticket_number), IsNotNull(ss_item_sk), IsNotNull(ss_customer_sk), IsNotNull(ss_sold..., ReadSchema: struct<ss_sold_date_sk:int,ss_item_sk:int,ss_customer_sk:int,ss_store_sk:int,ss_ticket_number:int...
               :     :     :     :     :     :     +- BroadcastExchange HashedRelationBroadcastMode(List(input[2, bigint, true], input[1, bigint, true], input[3, bigint, true]))
               :     :     :     :     :     :        +- *(1) Project [sr_returned_date_sk#25, sr_item_sk#30, sr_customer_sk#29, sr_ticket_number#35, sr_return_quantity#17]
               :     :     :     :     :     :           +- *(1) Filter (((isnotnull(sr_ticket_number#35) && isnotnull(sr_item_sk#30)) && isnotnull(sr_customer_sk#29)) && isnotnull(sr_returned_date_sk#25))
               :     :     :     :     :     :              +- *(1) FileScan parquet default.store_returns[sr_returned_date_sk#25,sr_item_sk#30,sr_customer_sk#29,sr_ticket_number#35,sr_return_quantity#17] Batched: true, Format: Parquet, Location: InMemoryFileIndex[file:/C:/Users/apdave/github/hyperspace-1/spark-warehouse/store_returns], PartitionFilters: [], PushedFilters: [IsNotNull(sr_ticket_number), IsNotNull(sr_item_sk), IsNotNull(sr_customer_sk), IsNotNull(sr_retu..., ReadSchema: struct<sr_returned_date_sk:bigint,sr_item_sk:bigint,sr_customer_sk:bigint,sr_ticket_number:bigint...
               :     :     :     :     :     +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[1, int, true] as bigint), cast(input[2, int, true] as bigint)))
               :     :     :     :     :        +- *(2) Project [cs_sold_date_sk#23, cs_bill_customer_sk#31, cs_item_sk#32, cs_quantity#18]
               :     :     :     :     :           +- *(2) Filter ((isnotnull(cs_item_sk#32) && isnotnull(cs_bill_customer_sk#31)) && isnotnull(cs_sold_date_sk#23))
               :     :     :     :     :              +- *(2) FileScan parquet default.catalog_sales[cs_sold_date_sk#23,cs_bill_customer_sk#31,cs_item_sk#32,cs_quantity#18] Batched: true, Format: Parquet, Location: InMemoryFileIndex[file:/C:/Users/apdave/github/hyperspace-1/spark-warehouse/catalog_sales], PartitionFilters: [], PushedFilters: [IsNotNull(cs_item_sk), IsNotNull(cs_bill_customer_sk), IsNotNull(cs_sold_date_sk)], ReadSchema: struct<cs_sold_date_sk:int,cs_bill_customer_sk:int,cs_item_sk:int,cs_quantity:int>
               :     :     :     :     +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)))
               :     :     :     :        +- *(3) Project [d_date_sk#28]
               :     :     :     :           +- *(3) Filter ((isnotnull(d_quarter_name#36) && (d_quarter_name#36 = 2001Q1)) && isnotnull(d_date_sk#28))
               :     :     :     :              +- *(3) FileScan parquet default.date_dim[d_date_sk#28,d_quarter_name#36] Batched: true, Format: Parquet, Location: InMemoryFileIndex[file:/C:/Users/apdave/github/hyperspace-1/spark-warehouse/date_dim], PartitionFilters: [], PushedFilters: [IsNotNull(d_quarter_name), EqualTo(d_quarter_name,2001Q1), IsNotNull(d_date_sk)], ReadSchema: struct<d_date_sk:int,d_quarter_name:string>
               :     :     :     +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)))
               :     :     :        +- *(4) Project [d_date_sk#26]
               :     :     :           +- *(4) Filter (d_quarter_name#37 IN (2001Q1,2001Q2,2001Q3) && isnotnull(d_date_sk#26))
               :     :     :              +- *(4) FileScan parquet default.date_dim[d_date_sk#26,d_quarter_name#37] Batched: true, Format: Parquet, Location: InMemoryFileIndex[file:/C:/Users/apdave/github/hyperspace-1/spark-warehouse/date_dim], PartitionFilters: [], PushedFilters: [In(d_quarter_name, [2001Q1,2001Q2,2001Q3]), IsNotNull(d_date_sk)], ReadSchema: struct<d_date_sk:int,d_quarter_name:string>
               :     :     +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)))
               :     :        +- *(5) Project [d_date_sk#24]
               :     :           +- *(5) Filter (d_quarter_name#38 IN (2001Q1,2001Q2,2001Q3) && isnotnull(d_date_sk#24))
               :     :              +- *(5) FileScan parquet default.date_dim[d_date_sk#24,d_quarter_name#38] Batched: true, Format: Parquet, Location: InMemoryFileIndex[file:/C:/Users/apdave/github/hyperspace-1/spark-warehouse/date_dim], PartitionFilters: [], PushedFilters: [In(d_quarter_name, [2001Q1,2001Q2,2001Q3]), IsNotNull(d_date_sk)], ReadSchema: struct<d_date_sk:int,d_quarter_name:string>
               :     +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)))
               :        +- *(6) Project [s_store_sk#22, s_state#3]
               :           +- *(6) Filter isnotnull(s_store_sk#22)
               :              +- *(6) FileScan parquet default.store[s_store_sk#22,s_state#3] Batched: true, Format: Parquet, Location: InMemoryFileIndex[file:/C:/Users/apdave/github/hyperspace-1/spark-warehouse/store], PartitionFilters: [], PushedFilters: [IsNotNull(s_store_sk)], ReadSchema: struct<s_store_sk:int,s_state:string>
               +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)))
                  +- *(7) Project [i_item_sk#20, i_item_id#1, i_item_desc#2]
                     +- *(7) Filter isnotnull(i_item_sk#20)
                        +- *(7) FileScan parquet default.item[i_item_sk#20,i_item_id#1,i_item_desc#2] Batched: true, Format: Parquet, Location: InMemoryFileIndex[file:/C:/Users/apdave/github/hyperspace-1/spark-warehouse/item], PartitionFilters: [], PushedFilters: [IsNotNull(i_item_sk)], ReadSchema: struct<i_item_sk:int,i_item_id:string,i_item_desc:string>