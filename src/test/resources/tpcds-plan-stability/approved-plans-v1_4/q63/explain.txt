== Physical Plan ==
TakeOrderedAndProject(limit=100, orderBy=[i_manager_id#1 ASC NULLS FIRST,avg_monthly_sales#2 ASC NULLS FIRST,sum_sales#3 ASC NULLS FIRST], output=[i_manager_id#1,sum_sales#3,avg_monthly_sales#2])
+- *(7) Project [i_manager_id#1, sum_sales#3, avg_monthly_sales#2]
   +- *(7) Filter (CASE WHEN (avg_monthly_sales#2 > 0.000000) THEN CheckOverflow((promote_precision(abs(CheckOverflow((promote_precision(cast(sum_sales#3 as decimal(22,6))) - promote_precision(cast(avg_monthly_sales#2 as decimal(22,6)))), DecimalType(22,6)))) / promote_precision(cast(avg_monthly_sales#2 as decimal(22,6)))), DecimalType(38,16)) ELSE null END > 0.1000000000000000)
      +- Window [avg(_w0#4) windowspecdefinition(i_manager_id#1, specifiedwindowframe(RowFrame, unboundedpreceding$(), unboundedfollowing$())) AS avg_monthly_sales#2], [i_manager_id#1]
         +- *(6) Sort [i_manager_id#1 ASC NULLS FIRST], false, 0
            +- Exchange hashpartitioning(i_manager_id#1, 200)
               +- *(5) HashAggregate(keys=[i_manager_id#1, d_moy#5], functions=[sum(UnscaledValue(ss_sales_price#6))])
                  +- Exchange hashpartitioning(i_manager_id#1, d_moy#5, 200)
                     +- *(4) HashAggregate(keys=[i_manager_id#1, d_moy#5], functions=[partial_sum(UnscaledValue(ss_sales_price#6))])
                        +- *(4) Project [i_manager_id#1, ss_sales_price#6, d_moy#5]
                           +- *(4) BroadcastHashJoin [ss_store_sk#7], [s_store_sk#8], Inner, BuildRight
                              :- *(4) Project [i_manager_id#1, ss_store_sk#7, ss_sales_price#6, d_moy#5]
                              :  +- *(4) BroadcastHashJoin [ss_sold_date_sk#9], [d_date_sk#10], Inner, BuildRight
                              :     :- *(4) Project [i_manager_id#1, ss_sold_date_sk#9, ss_store_sk#7, ss_sales_price#6]
                              :     :  +- *(4) BroadcastHashJoin [i_item_sk#11], [ss_item_sk#12], Inner, BuildRight
                              :     :     :- *(4) Project [i_item_sk#11, i_manager_id#1]
                              :     :     :  +- *(4) Filter ((((i_category#13 IN (Books,Children,Electronics) && i_class#14 IN (personal,portable,refernece,self-help)) && i_brand#15 IN (scholaramalgamalg #16,scholaramalgamalg #17,exportiunivamalg #18,scholaramalgamalg #18)) || ((i_category#13 IN (Women,Music,Men) && i_class#14 IN (accessories,classical,fragrances,pants)) && i_brand#15 IN (amalgimporto #19,edu packscholar #19,exportiimporto #19,importoamalg #19))) && isnotnull(i_item_sk#11))
                              :     :     :     +- *(4) FileScan parquet default.item[i_item_sk#11,i_brand#15,i_class#14,i_category#13,i_manager_id#1] Batched: true, Format: Parquet, Location: InMemoryFileIndex[file:/C:/Users/apdave/github/hyperspace-1/spark-warehouse/item], PartitionFilters: [], PushedFilters: [Or(And(And(In(i_category, [Books,Children,Electronics]),In(i_class, [personal,portable,refernece..., ReadSchema: struct<i_item_sk:int,i_brand:string,i_class:string,i_category:string,i_manager_id:int>
                              :     :     +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[1, int, true] as bigint)))
                              :     :        +- *(1) Project [ss_sold_date_sk#9, ss_item_sk#12, ss_store_sk#7, ss_sales_price#6]
                              :     :           +- *(1) Filter ((isnotnull(ss_item_sk#12) && isnotnull(ss_sold_date_sk#9)) && isnotnull(ss_store_sk#7))
                              :     :              +- *(1) FileScan parquet default.store_sales[ss_sold_date_sk#9,ss_item_sk#12,ss_store_sk#7,ss_sales_price#6] Batched: true, Format: Parquet, Location: InMemoryFileIndex[file:/C:/Users/apdave/github/hyperspace-1/spark-warehouse/store_sales], PartitionFilters: [], PushedFilters: [IsNotNull(ss_item_sk), IsNotNull(ss_sold_date_sk), IsNotNull(ss_store_sk)], ReadSchema: struct<ss_sold_date_sk:int,ss_item_sk:int,ss_store_sk:int,ss_sales_price:decimal(7,2)>
                              :     +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)))
                              :        +- *(2) Project [d_date_sk#10, d_moy#5]
                              :           +- *(2) Filter (d_month_seq#20 INSET (1200,1211,1205,1201,1206,1210,1207,1202,1209,1203,1208,1204) && isnotnull(d_date_sk#10))
                              :              +- *(2) FileScan parquet default.date_dim[d_date_sk#10,d_month_seq#20,d_moy#5] Batched: true, Format: Parquet, Location: InMemoryFileIndex[file:/C:/Users/apdave/github/hyperspace-1/spark-warehouse/date_dim], PartitionFilters: [], PushedFilters: [In(d_month_seq, [1200,1211,1205,1201,1206,1210,1207,1202,1209,1203,1208,1204]), IsNotNull(d_date..., ReadSchema: struct<d_date_sk:int,d_month_seq:int,d_moy:int>
                              +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)))
                                 +- *(3) Project [s_store_sk#8]
                                    +- *(3) Filter isnotnull(s_store_sk#8)
                                       +- *(3) FileScan parquet default.store[s_store_sk#8] Batched: true, Format: Parquet, Location: InMemoryFileIndex[file:/C:/Users/apdave/github/hyperspace-1/spark-warehouse/store], PartitionFilters: [], PushedFilters: [IsNotNull(s_store_sk)], ReadSchema: struct<s_store_sk:int>