== Physical Plan ==
*(7) Sort [c_last_name#1 ASC NULLS FIRST, c_first_name#2 ASC NULLS FIRST, c_salutation#3 ASC NULLS FIRST, c_preferred_cust_flag#4 DESC NULLS LAST], true, 0
+- Exchange rangepartitioning(c_last_name#1 ASC NULLS FIRST, c_first_name#2 ASC NULLS FIRST, c_salutation#3 ASC NULLS FIRST, c_preferred_cust_flag#4 DESC NULLS LAST, 5)
   +- *(6) Project [c_last_name#1, c_first_name#2, c_salutation#3, c_preferred_cust_flag#4, ss_ticket_number#5, cnt#6]
      +- *(6) BroadcastHashJoin [ss_customer_sk#7], [c_customer_sk#8], Inner, BuildRight
         :- *(6) Filter ((cnt#6 >= 15) && (cnt#6 <= 20))
         :  +- *(6) HashAggregate(keys=[ss_ticket_number#5, ss_customer_sk#7], functions=[count(1)])
         :     +- Exchange hashpartitioning(ss_ticket_number#5, ss_customer_sk#7, 5)
         :        +- *(4) HashAggregate(keys=[ss_ticket_number#5, ss_customer_sk#7], functions=[partial_count(1)])
         :           +- *(4) Project [ss_customer_sk#7, ss_ticket_number#5]
         :              +- *(4) BroadcastHashJoin [ss_hdemo_sk#9], [hd_demo_sk#10], Inner, BuildRight
         :                 :- *(4) Project [ss_customer_sk#7, ss_hdemo_sk#9, ss_ticket_number#5]
         :                 :  +- *(4) BroadcastHashJoin [ss_store_sk#11], [s_store_sk#12], Inner, BuildRight
         :                 :     :- *(4) Project [ss_customer_sk#7, ss_hdemo_sk#9, ss_store_sk#11, ss_ticket_number#5]
         :                 :     :  +- *(4) BroadcastHashJoin [ss_sold_date_sk#13], [d_date_sk#14], Inner, BuildRight
         :                 :     :     :- *(4) Project [ss_sold_date_sk#13, ss_customer_sk#7, ss_hdemo_sk#9, ss_store_sk#11, ss_ticket_number#5]
         :                 :     :     :  +- *(4) Filter (((isnotnull(ss_sold_date_sk#13) && isnotnull(ss_store_sk#11)) && isnotnull(ss_hdemo_sk#9)) && isnotnull(ss_customer_sk#7))
         :                 :     :     :     +- *(4) FileScan parquet default.store_sales[ss_sold_date_sk#13,ss_customer_sk#7,ss_hdemo_sk#9,ss_store_sk#11,ss_ticket_number#5] Batched: true, Format: Parquet, Location: InMemoryFileIndex[file:/C:/Users/apdave/github/hyperspace-1/spark-warehouse/store_sales], PartitionFilters: [], PushedFilters: [IsNotNull(ss_sold_date_sk), IsNotNull(ss_store_sk), IsNotNull(ss_hdemo_sk), IsNotNull(ss_custome..., ReadSchema: struct<ss_sold_date_sk:int,ss_customer_sk:int,ss_hdemo_sk:int,ss_store_sk:int,ss_ticket_number:int>
         :                 :     :     +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)))
         :                 :     :        +- *(1) Project [d_date_sk#14]
         :                 :     :           +- *(1) Filter (((((d_dom#15 >= 1) && (d_dom#15 <= 3)) || ((d_dom#15 >= 25) && (d_dom#15 <= 28))) && d_year#16 IN (1999,2000,2001)) && isnotnull(d_date_sk#14))
         :                 :     :              +- *(1) FileScan parquet default.date_dim[d_date_sk#14,d_year#16,d_dom#15] Batched: true, Format: Parquet, Location: InMemoryFileIndex[file:/C:/Users/apdave/github/hyperspace-1/spark-warehouse/date_dim], PartitionFilters: [], PushedFilters: [Or(And(GreaterThanOrEqual(d_dom,1),LessThanOrEqual(d_dom,3)),And(GreaterThanOrEqual(d_dom,25),Le..., ReadSchema: struct<d_date_sk:int,d_year:int,d_dom:int>
         :                 :     +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)))
         :                 :        +- *(2) Project [s_store_sk#12]
         :                 :           +- *(2) Filter ((isnotnull(s_county#17) && (s_county#17 = Williamson County)) && isnotnull(s_store_sk#12))
         :                 :              +- *(2) FileScan parquet default.store[s_store_sk#12,s_county#17] Batched: true, Format: Parquet, Location: InMemoryFileIndex[file:/C:/Users/apdave/github/hyperspace-1/spark-warehouse/store], PartitionFilters: [], PushedFilters: [IsNotNull(s_county), EqualTo(s_county,Williamson County), IsNotNull(s_store_sk)], ReadSchema: struct<s_store_sk:int,s_county:string>
         :                 +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)))
         :                    +- *(3) Project [hd_demo_sk#10]
         :                       +- *(3) Filter ((((isnotnull(hd_vehicle_count#18) && ((hd_buy_potential#19 = >10000) || (hd_buy_potential#19 = unknown))) && (hd_vehicle_count#18 > 0)) && (CASE WHEN (hd_vehicle_count#18 > 0) THEN (cast(hd_dep_count#20 as double) / cast(hd_vehicle_count#18 as double)) ELSE null END > 1.2)) && isnotnull(hd_demo_sk#10))
         :                          +- *(3) FileScan parquet default.household_demographics[hd_demo_sk#10,hd_buy_potential#19,hd_dep_count#20,hd_vehicle_count#18] Batched: true, Format: Parquet, Location: InMemoryFileIndex[file:/C:/Users/apdave/github/hyperspace-1/spark-warehouse/household_demographics], PartitionFilters: [], PushedFilters: [IsNotNull(hd_vehicle_count), Or(EqualTo(hd_buy_potential,>10000),EqualTo(hd_buy_potential,unknow..., ReadSchema: struct<hd_demo_sk:int,hd_buy_potential:string,hd_dep_count:int,hd_vehicle_count:int>
         +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)))
            +- *(5) Project [c_customer_sk#8, c_salutation#3, c_first_name#2, c_last_name#1, c_preferred_cust_flag#4]
               +- *(5) Filter isnotnull(c_customer_sk#8)
                  +- *(5) FileScan parquet default.customer[c_customer_sk#8,c_salutation#3,c_first_name#2,c_last_name#1,c_preferred_cust_flag#4] Batched: true, Format: Parquet, Location: InMemoryFileIndex[file:/C:/Users/apdave/github/hyperspace-1/spark-warehouse/customer], PartitionFilters: [], PushedFilters: [IsNotNull(c_customer_sk)], ReadSchema: struct<c_customer_sk:int,c_salutation:string,c_first_name:string,c_last_name:string,c_preferred_c...