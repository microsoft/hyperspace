== Physical Plan ==
TakeOrderedAndProject(limit=100, orderBy=[s_store_name#1 ASC NULLS FIRST], output=[s_store_name#1,sum(ss_net_profit)#2])
+- *(9) HashAggregate(keys=[s_store_name#1], functions=[sum(UnscaledValue(ss_net_profit#3))])
   +- Exchange hashpartitioning(s_store_name#1, 200)
      +- *(8) HashAggregate(keys=[s_store_name#1], functions=[partial_sum(UnscaledValue(ss_net_profit#3))])
         +- *(8) Project [ss_net_profit#3, s_store_name#1]
            +- *(8) BroadcastHashJoin [substring(s_zip#4, 1, 2)], [substring(ca_zip#5, 1, 2)], Inner, BuildRight
               :- *(8) Project [ss_net_profit#3, s_store_name#1, s_zip#4]
               :  +- *(8) BroadcastHashJoin [ss_store_sk#6], [s_store_sk#7], Inner, BuildRight
               :     :- *(8) Project [ss_store_sk#6, ss_net_profit#3]
               :     :  +- *(8) BroadcastHashJoin [ss_sold_date_sk#8], [d_date_sk#9], Inner, BuildRight
               :     :     :- *(8) Project [ss_sold_date_sk#8, ss_store_sk#6, ss_net_profit#3]
               :     :     :  +- *(8) Filter (isnotnull(ss_sold_date_sk#8) && isnotnull(ss_store_sk#6))
               :     :     :     +- *(8) FileScan parquet default.store_sales[ss_sold_date_sk#8,ss_store_sk#6,ss_net_profit#3] Batched: true, Format: Parquet, Location: InMemoryFileIndex[file:/C:/Users/apdave/github/hyperspace-1/spark-warehouse/store_sales], PartitionFilters: [], PushedFilters: [IsNotNull(ss_sold_date_sk), IsNotNull(ss_store_sk)], ReadSchema: struct<ss_sold_date_sk:int,ss_store_sk:int,ss_net_profit:decimal(7,2)>
               :     :     +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)))
               :     :        +- *(1) Project [d_date_sk#9]
               :     :           +- *(1) Filter ((((isnotnull(d_qoy#10) && isnotnull(d_year#11)) && (d_qoy#10 = 2)) && (d_year#11 = 1998)) && isnotnull(d_date_sk#9))
               :     :              +- *(1) FileScan parquet default.date_dim[d_date_sk#9,d_year#11,d_qoy#10] Batched: true, Format: Parquet, Location: InMemoryFileIndex[file:/C:/Users/apdave/github/hyperspace-1/spark-warehouse/date_dim], PartitionFilters: [], PushedFilters: [IsNotNull(d_qoy), IsNotNull(d_year), EqualTo(d_qoy,2), EqualTo(d_year,1998), IsNotNull(d_date_sk)], ReadSchema: struct<d_date_sk:int,d_year:int,d_qoy:int>
               :     +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)))
               :        +- *(2) Project [s_store_sk#7, s_store_name#1, s_zip#4]
               :           +- *(2) Filter (isnotnull(s_store_sk#7) && isnotnull(s_zip#4))
               :              +- *(2) FileScan parquet default.store[s_store_sk#7,s_store_name#1,s_zip#4] Batched: true, Format: Parquet, Location: InMemoryFileIndex[file:/C:/Users/apdave/github/hyperspace-1/spark-warehouse/store], PartitionFilters: [], PushedFilters: [IsNotNull(s_store_sk), IsNotNull(s_zip)], ReadSchema: struct<s_store_sk:int,s_store_name:string,s_zip:string>
               +- BroadcastExchange HashedRelationBroadcastMode(List(substring(input[0, string, true], 1, 2)))
                  +- *(7) HashAggregate(keys=[ca_zip#5], functions=[])
                     +- Exchange hashpartitioning(ca_zip#5, 200)
                        +- *(6) HashAggregate(keys=[ca_zip#5], functions=[])
                           +- *(6) BroadcastHashJoin [coalesce(ca_zip#5, )], [coalesce(ca_zip#12, )], LeftSemi, BuildRight, (ca_zip#5 <=> ca_zip#12)
                              :- *(6) Project [substring(ca_zip#13, 1, 5) AS ca_zip#5]
                              :  +- *(6) Filter (substring(ca_zip#13, 1, 5) INSET (56910,69952,63792,39371,74351,11101,25003,97189,57834,73134,62377,51200,32754,22752,86379,14171,91110,40162,98569,28709,13394,66162,25733,25782,26065,18383,51949,87343,50298,83849,33786,64528,23470,67030,46136,25280,46820,77721,99076,18426,31880,17871,98235,45748,49156,18652,72013,51622,43848,78567,41248,13695,44165,67853,54917,53179,64034,10567,71791,68908,55565,59402,64147,85816,57855,61547,27700,68100,28810,58263,15723,83933,51103,58058,90578,82276,81096,81426,96451,77556,38607,76638,18906,62971,57047,48425,35576,11928,30625,83444,73520,51650,57647,60099,30122,94983,24128,10445,41368,26233,26859,21756,24676,19849,36420,38193,58470,39127,13595,87501,24317,15455,69399,98025,81019,48033,11376,39516,67875,92712,14867,38122,29741,42961,30469,51211,56458,15559,16021,33123,33282,33515,72823,54601,76698,56240,72175,60279,20004,68806,72325,28488,43933,50412,45200,22246,78668,79777,96765,67301,73273,49448,82636,23932,47305,29839,39192,18799,61265,37125,58943,64457,88424,24610,84935,89360,68893,30431,28898,10336,90257,59166,46081,26105,96888,36634,86284,35258,39972,22927,73241,53268,24206,27385,99543,31671,14663,30903,39861,24996,63089,88086,83921,21076,67897,66708,45721,60576,25103,52867,30450,36233,30010,96576,73171,56571,56575,64544,13955,78451,43285,18119,16725,83041,76107,79994,54364,35942,56691,19769,63435,34102,18845,22744,13354,75691,45549,23968,31387,83144,13375,15765,28577,88190,19736,73650,37930,25989,83926,94898,51798,39736,22437,55253,38415,71256,18376,42029,25858,44438,19515,38935,51649,71954,15882,18767,63193,25486,49130,37126,40604,34425,17043,12305,11634,26653,94167,36446,10516,67473,66864,72425,63981,18842,22461,42666,47770,69035,70372,28587,45266,15371,15798,45375,90225,16807,31016,68014,21337,19505,50016,10144,84093,21286,19430,34322,91068,94945,72305,24671,58048,65084,28545,21195,20548,22245,77191,96976,48583,76231,15734,61810,11356,68621,68786,98359,41367,26689,69913,76614,68101,88885,50308,79077,18270,28915,29178,53672,62878,10390,14922,68341,56529,41766,68309,56616,15126,61860,97789,11489,45692,41918,72151,72550,27156,36495,70738,17879,53535,17920,68880,78890,35850,14089,58078,65164,27068,26231,13376,57665,32213,77610,87816,21309,15146,86198,91137,55307,67467,40558,94627,82136,22351,89091,20260,23006,91393,47537,62496,98294,18840,71286,81312,31029,70466,35458,14060,22685,28286,25631,19512,40081,63837,14328,35474,22152,76232,51061,86057,17183) && isnotnull(substring(ca_zip#13, 1, 5)))
                              :     +- *(6) FileScan parquet default.customer_address[ca_zip#13] Batched: true, Format: Parquet, Location: InMemoryFileIndex[file:/C:/Users/apdave/github/hyperspace-1/spark-warehouse/customer_address], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<ca_zip:string>
                              +- BroadcastExchange HashedRelationBroadcastMode(List(coalesce(input[0, string, true], )))
                                 +- *(5) Project [ca_zip#12]
                                    +- *(5) Filter (count(1)#14 > 10)
                                       +- *(5) HashAggregate(keys=[ca_zip#13], functions=[count(1)])
                                          +- Exchange hashpartitioning(ca_zip#13, 200)
                                             +- *(4) HashAggregate(keys=[ca_zip#13], functions=[partial_count(1)])
                                                +- *(4) Project [ca_zip#13]
                                                   +- *(4) BroadcastHashJoin [ca_address_sk#15], [c_current_addr_sk#16], Inner, BuildRight
                                                      :- *(4) Project [ca_address_sk#15, ca_zip#13]
                                                      :  +- *(4) Filter isnotnull(ca_address_sk#15)
                                                      :     +- *(4) FileScan parquet default.customer_address[ca_address_sk#15,ca_zip#13] Batched: true, Format: Parquet, Location: InMemoryFileIndex[file:/C:/Users/apdave/github/hyperspace-1/spark-warehouse/customer_address], PartitionFilters: [], PushedFilters: [IsNotNull(ca_address_sk)], ReadSchema: struct<ca_address_sk:int,ca_zip:string>
                                                      +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)))
                                                         +- *(3) Project [c_current_addr_sk#16]
                                                            +- *(3) Filter ((isnotnull(c_preferred_cust_flag#17) && (c_preferred_cust_flag#17 = Y)) && isnotnull(c_current_addr_sk#16))
                                                               +- *(3) FileScan parquet default.customer[c_current_addr_sk#16,c_preferred_cust_flag#17] Batched: true, Format: Parquet, Location: InMemoryFileIndex[file:/C:/Users/apdave/github/hyperspace-1/spark-warehouse/customer], PartitionFilters: [], PushedFilters: [IsNotNull(c_preferred_cust_flag), EqualTo(c_preferred_cust_flag,Y), IsNotNull(c_current_addr_sk)], ReadSchema: struct<c_current_addr_sk:int,c_preferred_cust_flag:string>