== Physical Plan ==
TakeOrderedAndProject(limit=100, orderBy=[channel#1 ASC NULLS FIRST,id#2 ASC NULLS FIRST], output=[channel#1,id#2,sales#3,returns#4,profit#5])
+- *(23) HashAggregate(keys=[channel#1, id#2, spark_grouping_id#6], functions=[sum(sales#7), sum(returns#8), sum(profit#9)])
   +- Exchange hashpartitioning(channel#1, id#2, spark_grouping_id#6, 200)
      +- *(22) HashAggregate(keys=[channel#1, id#2, spark_grouping_id#6], functions=[partial_sum(sales#7), partial_sum(returns#8), partial_sum(profit#9)])
         +- *(22) Expand [List(sales#7, returns#8, profit#9, channel#10, id#11, 0), List(sales#7, returns#8, profit#9, channel#10, null, 1), List(sales#7, returns#8, profit#9, null, null, 3)], [sales#7, returns#8, profit#9, channel#1, id#2, spark_grouping_id#6]
            +- Union
               :- *(7) HashAggregate(keys=[s_store_id#12], functions=[sum(UnscaledValue(ss_ext_sales_price#13)), sum(coalesce(cast(sr_return_amt#14 as decimal(12,2)), 0.00)), sum(CheckOverflow((promote_precision(cast(ss_net_profit#15 as decimal(13,2))) - promote_precision(cast(coalesce(cast(sr_net_loss#16 as decimal(12,2)), 0.00) as decimal(13,2)))), DecimalType(13,2)))])
               :  +- Exchange hashpartitioning(s_store_id#12, 200)
               :     +- *(6) HashAggregate(keys=[s_store_id#12], functions=[partial_sum(UnscaledValue(ss_ext_sales_price#13)), partial_sum(coalesce(cast(sr_return_amt#14 as decimal(12,2)), 0.00)), partial_sum(CheckOverflow((promote_precision(cast(ss_net_profit#15 as decimal(13,2))) - promote_precision(cast(coalesce(cast(sr_net_loss#16 as decimal(12,2)), 0.00) as decimal(13,2)))), DecimalType(13,2)))])
               :        +- *(6) Project [ss_ext_sales_price#13, ss_net_profit#15, sr_return_amt#14, sr_net_loss#16, s_store_id#12]
               :           +- *(6) BroadcastHashJoin [ss_promo_sk#17], [p_promo_sk#18], Inner, BuildRight
               :              :- *(6) Project [ss_promo_sk#17, ss_ext_sales_price#13, ss_net_profit#15, sr_return_amt#14, sr_net_loss#16, s_store_id#12]
               :              :  +- *(6) BroadcastHashJoin [ss_item_sk#19], [i_item_sk#20], Inner, BuildRight
               :              :     :- *(6) Project [ss_item_sk#19, ss_promo_sk#17, ss_ext_sales_price#13, ss_net_profit#15, sr_return_amt#14, sr_net_loss#16, s_store_id#12]
               :              :     :  +- *(6) BroadcastHashJoin [ss_store_sk#21], [s_store_sk#22], Inner, BuildRight
               :              :     :     :- *(6) Project [ss_item_sk#19, ss_store_sk#21, ss_promo_sk#17, ss_ext_sales_price#13, ss_net_profit#15, sr_return_amt#14, sr_net_loss#16]
               :              :     :     :  +- *(6) BroadcastHashJoin [ss_sold_date_sk#23], [d_date_sk#24], Inner, BuildRight
               :              :     :     :     :- *(6) Project [ss_sold_date_sk#23, ss_item_sk#19, ss_store_sk#21, ss_promo_sk#17, ss_ext_sales_price#13, ss_net_profit#15, sr_return_amt#14, sr_net_loss#16]
               :              :     :     :     :  +- *(6) BroadcastHashJoin [cast(ss_item_sk#19 as bigint), cast(ss_ticket_number#25 as bigint)], [sr_item_sk#26, sr_ticket_number#27], LeftOuter, BuildRight
               :              :     :     :     :     :- *(6) Project [ss_sold_date_sk#23, ss_item_sk#19, ss_store_sk#21, ss_promo_sk#17, ss_ticket_number#25, ss_ext_sales_price#13, ss_net_profit#15]
               :              :     :     :     :     :  +- *(6) Filter (((isnotnull(ss_sold_date_sk#23) && isnotnull(ss_store_sk#21)) && isnotnull(ss_item_sk#19)) && isnotnull(ss_promo_sk#17))
               :              :     :     :     :     :     +- *(6) FileScan parquet default.store_sales[ss_sold_date_sk#23,ss_item_sk#19,ss_store_sk#21,ss_promo_sk#17,ss_ticket_number#25,ss_ext_sales_price#13,ss_net_profit#15] Batched: true, Format: Parquet, Location: InMemoryFileIndex[file:/C:/Users/apdave/github/hyperspace-1/spark-warehouse/store_sales], PartitionFilters: [], PushedFilters: [IsNotNull(ss_sold_date_sk), IsNotNull(ss_store_sk), IsNotNull(ss_item_sk), IsNotNull(ss_promo_sk)], ReadSchema: struct<ss_sold_date_sk:int,ss_item_sk:int,ss_store_sk:int,ss_promo_sk:int,ss_ticket_number:int,ss...
               :              :     :     :     :     +- BroadcastExchange HashedRelationBroadcastMode(List(input[0, bigint, true], input[1, bigint, true]))
               :              :     :     :     :        +- *(1) Project [sr_item_sk#26, sr_ticket_number#27, sr_return_amt#14, sr_net_loss#16]
               :              :     :     :     :           +- *(1) Filter (isnotnull(sr_item_sk#26) && isnotnull(sr_ticket_number#27))
               :              :     :     :     :              +- *(1) FileScan parquet default.store_returns[sr_item_sk#26,sr_ticket_number#27,sr_return_amt#14,sr_net_loss#16] Batched: true, Format: Parquet, Location: InMemoryFileIndex[file:/C:/Users/apdave/github/hyperspace-1/spark-warehouse/store_returns], PartitionFilters: [], PushedFilters: [IsNotNull(sr_item_sk), IsNotNull(sr_ticket_number)], ReadSchema: struct<sr_item_sk:bigint,sr_ticket_number:bigint,sr_return_amt:decimal(7,2),sr_net_loss:decimal(7...
               :              :     :     :     +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)))
               :              :     :     :        +- *(2) Project [d_date_sk#24]
               :              :     :     :           +- *(2) Filter (((isnotnull(d_date#28) && (d_date#28 >= 11192)) && (d_date#28 <= 11222)) && isnotnull(d_date_sk#24))
               :              :     :     :              +- *(2) FileScan parquet default.date_dim[d_date_sk#24,d_date#28] Batched: true, Format: Parquet, Location: InMemoryFileIndex[file:/C:/Users/apdave/github/hyperspace-1/spark-warehouse/date_dim], PartitionFilters: [], PushedFilters: [IsNotNull(d_date), GreaterThanOrEqual(d_date,2000-08-23), LessThanOrEqual(d_date,2000-09-22), Is..., ReadSchema: struct<d_date_sk:int,d_date:date>
               :              :     :     +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)))
               :              :     :        +- *(3) Project [s_store_sk#22, s_store_id#12]
               :              :     :           +- *(3) Filter isnotnull(s_store_sk#22)
               :              :     :              +- *(3) FileScan parquet default.store[s_store_sk#22,s_store_id#12] Batched: true, Format: Parquet, Location: InMemoryFileIndex[file:/C:/Users/apdave/github/hyperspace-1/spark-warehouse/store], PartitionFilters: [], PushedFilters: [IsNotNull(s_store_sk)], ReadSchema: struct<s_store_sk:int,s_store_id:string>
               :              :     +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)))
               :              :        +- *(4) Project [i_item_sk#20]
               :              :           +- *(4) Filter ((isnotnull(i_current_price#29) && (i_current_price#29 > 50.00)) && isnotnull(i_item_sk#20))
               :              :              +- *(4) FileScan parquet default.item[i_item_sk#20,i_current_price#29] Batched: true, Format: Parquet, Location: InMemoryFileIndex[file:/C:/Users/apdave/github/hyperspace-1/spark-warehouse/item], PartitionFilters: [], PushedFilters: [IsNotNull(i_current_price), GreaterThan(i_current_price,50.00), IsNotNull(i_item_sk)], ReadSchema: struct<i_item_sk:int,i_current_price:decimal(7,2)>
               :              +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)))
               :                 +- *(5) Project [p_promo_sk#18]
               :                    +- *(5) Filter ((isnotnull(p_channel_tv#30) && (p_channel_tv#30 = N)) && isnotnull(p_promo_sk#18))
               :                       +- *(5) FileScan parquet default.promotion[p_promo_sk#18,p_channel_tv#30] Batched: true, Format: Parquet, Location: InMemoryFileIndex[file:/C:/Users/apdave/github/hyperspace-1/spark-warehouse/promotion], PartitionFilters: [], PushedFilters: [IsNotNull(p_channel_tv), EqualTo(p_channel_tv,N), IsNotNull(p_promo_sk)], ReadSchema: struct<p_promo_sk:int,p_channel_tv:string>
               :- *(14) HashAggregate(keys=[cp_catalog_page_id#31], functions=[sum(UnscaledValue(cs_ext_sales_price#32)), sum(coalesce(cast(cr_return_amount#33 as decimal(12,2)), 0.00)), sum(CheckOverflow((promote_precision(cast(cs_net_profit#34 as decimal(13,2))) - promote_precision(cast(coalesce(cast(cr_net_loss#35 as decimal(12,2)), 0.00) as decimal(13,2)))), DecimalType(13,2)))])
               :  +- Exchange hashpartitioning(cp_catalog_page_id#31, 200)
               :     +- *(13) HashAggregate(keys=[cp_catalog_page_id#31], functions=[partial_sum(UnscaledValue(cs_ext_sales_price#32)), partial_sum(coalesce(cast(cr_return_amount#33 as decimal(12,2)), 0.00)), partial_sum(CheckOverflow((promote_precision(cast(cs_net_profit#34 as decimal(13,2))) - promote_precision(cast(coalesce(cast(cr_net_loss#35 as decimal(12,2)), 0.00) as decimal(13,2)))), DecimalType(13,2)))])
               :        +- *(13) Project [cs_ext_sales_price#32, cs_net_profit#34, cr_return_amount#33, cr_net_loss#35, cp_catalog_page_id#31]
               :           +- *(13) BroadcastHashJoin [cs_promo_sk#36], [p_promo_sk#18], Inner, BuildRight
               :              :- *(13) Project [cs_promo_sk#36, cs_ext_sales_price#32, cs_net_profit#34, cr_return_amount#33, cr_net_loss#35, cp_catalog_page_id#31]
               :              :  +- *(13) BroadcastHashJoin [cs_item_sk#37], [i_item_sk#20], Inner, BuildRight
               :              :     :- *(13) Project [cs_item_sk#37, cs_promo_sk#36, cs_ext_sales_price#32, cs_net_profit#34, cr_return_amount#33, cr_net_loss#35, cp_catalog_page_id#31]
               :              :     :  +- *(13) BroadcastHashJoin [cs_catalog_page_sk#38], [cp_catalog_page_sk#39], Inner, BuildRight
               :              :     :     :- *(13) Project [cs_catalog_page_sk#38, cs_item_sk#37, cs_promo_sk#36, cs_ext_sales_price#32, cs_net_profit#34, cr_return_amount#33, cr_net_loss#35]
               :              :     :     :  +- *(13) BroadcastHashJoin [cs_sold_date_sk#40], [d_date_sk#24], Inner, BuildRight
               :              :     :     :     :- *(13) Project [cs_sold_date_sk#40, cs_catalog_page_sk#38, cs_item_sk#37, cs_promo_sk#36, cs_ext_sales_price#32, cs_net_profit#34, cr_return_amount#33, cr_net_loss#35]
               :              :     :     :     :  +- *(13) BroadcastHashJoin [cs_item_sk#37, cs_order_number#41], [cr_item_sk#42, cr_order_number#43], LeftOuter, BuildRight
               :              :     :     :     :     :- *(13) Project [cs_sold_date_sk#40, cs_catalog_page_sk#38, cs_item_sk#37, cs_promo_sk#36, cs_order_number#41, cs_ext_sales_price#32, cs_net_profit#34]
               :              :     :     :     :     :  +- *(13) Filter (((isnotnull(cs_sold_date_sk#40) && isnotnull(cs_catalog_page_sk#38)) && isnotnull(cs_item_sk#37)) && isnotnull(cs_promo_sk#36))
               :              :     :     :     :     :     +- *(13) FileScan parquet default.catalog_sales[cs_sold_date_sk#40,cs_catalog_page_sk#38,cs_item_sk#37,cs_promo_sk#36,cs_order_number#41,cs_ext_sales_price#32,cs_net_profit#34] Batched: true, Format: Parquet, Location: InMemoryFileIndex[file:/C:/Users/apdave/github/hyperspace-1/spark-warehouse/catalog_sales], PartitionFilters: [], PushedFilters: [IsNotNull(cs_sold_date_sk), IsNotNull(cs_catalog_page_sk), IsNotNull(cs_item_sk), IsNotNull(cs_p..., ReadSchema: struct<cs_sold_date_sk:int,cs_catalog_page_sk:int,cs_item_sk:int,cs_promo_sk:int,cs_order_number:...
               :              :     :     :     :     +- BroadcastExchange HashedRelationBroadcastMode(List((shiftleft(cast(input[0, int, true] as bigint), 32) | (cast(input[1, int, true] as bigint) & 4294967295))))
               :              :     :     :     :        +- *(8) Project [cr_item_sk#42, cr_order_number#43, cr_return_amount#33, cr_net_loss#35]
               :              :     :     :     :           +- *(8) Filter (isnotnull(cr_item_sk#42) && isnotnull(cr_order_number#43))
               :              :     :     :     :              +- *(8) FileScan parquet default.catalog_returns[cr_item_sk#42,cr_order_number#43,cr_return_amount#33,cr_net_loss#35] Batched: true, Format: Parquet, Location: InMemoryFileIndex[file:/C:/Users/apdave/github/hyperspace-1/spark-warehouse/catalog_returns], PartitionFilters: [], PushedFilters: [IsNotNull(cr_item_sk), IsNotNull(cr_order_number)], ReadSchema: struct<cr_item_sk:int,cr_order_number:int,cr_return_amount:decimal(7,2),cr_net_loss:decimal(7,2)>
               :              :     :     :     +- ReusedExchange [d_date_sk#24], BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)))
               :              :     :     +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)))
               :              :     :        +- *(10) Project [cp_catalog_page_sk#39, cp_catalog_page_id#31]
               :              :     :           +- *(10) Filter isnotnull(cp_catalog_page_sk#39)
               :              :     :              +- *(10) FileScan parquet default.catalog_page[cp_catalog_page_sk#39,cp_catalog_page_id#31] Batched: true, Format: Parquet, Location: InMemoryFileIndex[file:/C:/Users/apdave/github/hyperspace-1/spark-warehouse/catalog_page], PartitionFilters: [], PushedFilters: [IsNotNull(cp_catalog_page_sk)], ReadSchema: struct<cp_catalog_page_sk:int,cp_catalog_page_id:string>
               :              :     +- ReusedExchange [i_item_sk#20], BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)))
               :              +- ReusedExchange [p_promo_sk#18], BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)))
               +- *(21) HashAggregate(keys=[web_site_id#44], functions=[sum(UnscaledValue(ws_ext_sales_price#45)), sum(coalesce(cast(wr_return_amt#46 as decimal(12,2)), 0.00)), sum(CheckOverflow((promote_precision(cast(ws_net_profit#47 as decimal(13,2))) - promote_precision(cast(coalesce(cast(wr_net_loss#48 as decimal(12,2)), 0.00) as decimal(13,2)))), DecimalType(13,2)))])
                  +- Exchange hashpartitioning(web_site_id#44, 200)
                     +- *(20) HashAggregate(keys=[web_site_id#44], functions=[partial_sum(UnscaledValue(ws_ext_sales_price#45)), partial_sum(coalesce(cast(wr_return_amt#46 as decimal(12,2)), 0.00)), partial_sum(CheckOverflow((promote_precision(cast(ws_net_profit#47 as decimal(13,2))) - promote_precision(cast(coalesce(cast(wr_net_loss#48 as decimal(12,2)), 0.00) as decimal(13,2)))), DecimalType(13,2)))])
                        +- *(20) Project [ws_ext_sales_price#45, ws_net_profit#47, wr_return_amt#46, wr_net_loss#48, web_site_id#44]
                           +- *(20) BroadcastHashJoin [ws_promo_sk#49], [p_promo_sk#18], Inner, BuildRight
                              :- *(20) Project [ws_promo_sk#49, ws_ext_sales_price#45, ws_net_profit#47, wr_return_amt#46, wr_net_loss#48, web_site_id#44]
                              :  +- *(20) BroadcastHashJoin [ws_item_sk#50], [i_item_sk#20], Inner, BuildRight
                              :     :- *(20) Project [ws_item_sk#50, ws_promo_sk#49, ws_ext_sales_price#45, ws_net_profit#47, wr_return_amt#46, wr_net_loss#48, web_site_id#44]
                              :     :  +- *(20) BroadcastHashJoin [ws_web_site_sk#51], [web_site_sk#52], Inner, BuildRight
                              :     :     :- *(20) Project [ws_item_sk#50, ws_web_site_sk#51, ws_promo_sk#49, ws_ext_sales_price#45, ws_net_profit#47, wr_return_amt#46, wr_net_loss#48]
                              :     :     :  +- *(20) BroadcastHashJoin [ws_sold_date_sk#53], [d_date_sk#24], Inner, BuildRight
                              :     :     :     :- *(20) Project [ws_sold_date_sk#53, ws_item_sk#50, ws_web_site_sk#51, ws_promo_sk#49, ws_ext_sales_price#45, ws_net_profit#47, wr_return_amt#46, wr_net_loss#48]
                              :     :     :     :  +- *(20) BroadcastHashJoin [cast(ws_item_sk#50 as bigint), cast(ws_order_number#54 as bigint)], [wr_item_sk#55, wr_order_number#56], LeftOuter, BuildRight
                              :     :     :     :     :- *(20) Project [ws_sold_date_sk#53, ws_item_sk#50, ws_web_site_sk#51, ws_promo_sk#49, ws_order_number#54, ws_ext_sales_price#45, ws_net_profit#47]
                              :     :     :     :     :  +- *(20) Filter (((isnotnull(ws_sold_date_sk#53) && isnotnull(ws_web_site_sk#51)) && isnotnull(ws_item_sk#50)) && isnotnull(ws_promo_sk#49))
                              :     :     :     :     :     +- *(20) FileScan parquet default.web_sales[ws_sold_date_sk#53,ws_item_sk#50,ws_web_site_sk#51,ws_promo_sk#49,ws_order_number#54,ws_ext_sales_price#45,ws_net_profit#47] Batched: true, Format: Parquet, Location: InMemoryFileIndex[file:/C:/Users/apdave/github/hyperspace-1/spark-warehouse/web_sales], PartitionFilters: [], PushedFilters: [IsNotNull(ws_sold_date_sk), IsNotNull(ws_web_site_sk), IsNotNull(ws_item_sk), IsNotNull(ws_promo..., ReadSchema: struct<ws_sold_date_sk:int,ws_item_sk:int,ws_web_site_sk:int,ws_promo_sk:int,ws_order_number:int,...
                              :     :     :     :     +- BroadcastExchange HashedRelationBroadcastMode(List(input[0, bigint, true], input[1, bigint, true]))
                              :     :     :     :        +- *(15) Project [wr_item_sk#55, wr_order_number#56, wr_return_amt#46, wr_net_loss#48]
                              :     :     :     :           +- *(15) Filter (isnotnull(wr_item_sk#55) && isnotnull(wr_order_number#56))
                              :     :     :     :              +- *(15) FileScan parquet default.web_returns[wr_item_sk#55,wr_order_number#56,wr_return_amt#46,wr_net_loss#48] Batched: true, Format: Parquet, Location: InMemoryFileIndex[file:/C:/Users/apdave/github/hyperspace-1/spark-warehouse/web_returns], PartitionFilters: [], PushedFilters: [IsNotNull(wr_item_sk), IsNotNull(wr_order_number)], ReadSchema: struct<wr_item_sk:bigint,wr_order_number:bigint,wr_return_amt:decimal(7,2),wr_net_loss:decimal(7,2)>
                              :     :     :     +- ReusedExchange [d_date_sk#24], BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)))
                              :     :     +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)))
                              :     :        +- *(17) Project [web_site_sk#52, web_site_id#44]
                              :     :           +- *(17) Filter isnotnull(web_site_sk#52)
                              :     :              +- *(17) FileScan parquet default.web_site[web_site_sk#52,web_site_id#44] Batched: true, Format: Parquet, Location: InMemoryFileIndex[file:/C:/Users/apdave/github/hyperspace-1/spark-warehouse/web_site], PartitionFilters: [], PushedFilters: [IsNotNull(web_site_sk)], ReadSchema: struct<web_site_sk:int,web_site_id:string>
                              :     +- ReusedExchange [i_item_sk#20], BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)))
                              +- ReusedExchange [p_promo_sk#18], BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)))